{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb9a771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\macke\\desktop\\bachelorarbeit\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\macke\\desktop\\bachelorarbeit\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install timm==0.4.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9eadee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdd7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./evaluate')\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import torchvision\n",
    "from mae_utils import *\n",
    "import PIL\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90ba41",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946cfe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b26284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "Missing VQGAN keys: []\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "ckpt = r\"C:\\Users\\macke\\Desktop\\BachelorArbeit\\vtv-ckpt\\checkpoint-3400.pth\"\n",
    "model = prepare_model(ckpt, arch='mae_vit_large_patch16')\n",
    "\n",
    "model.eval()\n",
    "model = model.to()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a9ab1",
   "metadata": {},
   "source": [
    "## Setup utils and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3130d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A generalized imshow helper function which supports displaying (CxHxW) tensor\n",
    "def generalized_imshow(arr):\n",
    "    if isinstance(arr, torch.Tensor) and arr.shape[0] == 3:\n",
    "        arr = arr.permute(1, 2, 0)\n",
    "    plt.imshow(arr)\n",
    "    plt.show()\n",
    "    \n",
    "def crop_center(img,cropx,cropy):\n",
    "    y,x,_ = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "def create_grid_from_images(support_img, support_mask, query_img, query_mask, padding=1):\n",
    "    canvas = torch.zeros((support_img.shape[0], 2 * support_img.shape[1] + 2 * padding,\n",
    "                         2 * support_img.shape[2] + 2 * padding))\n",
    "    canvas[:, :support_img.shape[1], :support_img.shape[2]] = support_img\n",
    "    canvas[:, -query_img.shape[1]:, :query_img.shape[2]] = query_img\n",
    "    canvas[:, :support_img.shape[1], -support_img.shape[2]:] = support_mask\n",
    "    canvas[:, -query_img.shape[1]:, -support_img.shape[2]:] = query_mask\n",
    "\n",
    "    return canvas\n",
    "\n",
    "import torchvision\n",
    "padding = 1\n",
    "image_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize((224 // 2 - padding, 224 // 2 - padding)),\n",
    "     torchvision.transforms.ToTensor()])\n",
    "\n",
    "single_image_transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Resize((224, 224)),\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528a726",
   "metadata": {},
   "source": [
    "# Different functions to construct visual prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750e2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def url_to_pil(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    return img\n",
    "\n",
    "def run_model(source, target, new_source):\n",
    "    source = url_to_pil(source).convert('RGB')\n",
    "    target = url_to_pil(target).convert('RGB')\n",
    "    new_source =  url_to_pil(new_source).convert('RGB')\n",
    "\n",
    "    source = image_transform(source)\n",
    "    target = image_transform(target)\n",
    "    new_source = image_transform(new_source)\n",
    "    grid = create_grid_from_images(source, target, new_source, new_source)\n",
    "    grid = (grid - imagenet_mean[:,None,None]) / imagenet_std[:, None,None]\n",
    "    grid = grid[np.newaxis, :, :, :]\n",
    "    ids_shuffle, len_keep = generate_mask_for_evaluation()\n",
    "    grid = grid.to('cuda')\n",
    "    orig_image, im_paste, mask = generate_image(grid, model, ids_shuffle.to('cuda'), len_keep, device='cuda')\n",
    "    plt.figure(figsize=(8, 6), dpi=80)\n",
    "    return PIL.Image.fromarray(np.uint8(np.clip(im_paste.detach().cpu().numpy(), 0, 255)))\n",
    "    \n",
    "# load image, occlude bottom right part and predict the completion\n",
    "def run_model_single_img(img):\n",
    "    img = url_to_pil(img).convert('RGB')\n",
    "    img = single_image_transform(img)\n",
    "    grid = img[np.newaxis, :, :, :]\n",
    "    \n",
    "    \n",
    "    ids_shuffle, len_keep = generate_mask_for_evaluation()\n",
    "    grid = grid.to('cuda')\n",
    "    orig_image, im_paste, mask = generate_image(grid, model, ids_shuffle.to('cuda'), len_keep, device='cuda')\n",
    "    plt.figure(figsize=(8, 6), dpi=80)\n",
    "    return PIL.Image.fromarray(np.uint8(np.clip(im_paste.detach().cpu().numpy(), 0, 255)))\n",
    "\n",
    "def run_model_with_variable_placements(source, target, new_source):\n",
    "    source_p = url_to_pil(source).convert('RGB')\n",
    "    im = PIL.Image.new(mode=\"RGB\", size=(512, 512), color='white')\n",
    "    im.paste(source_p.resize((256,256)), (0, 0, 256, 256))\n",
    "    source = im\n",
    "\n",
    "    target_p = url_to_pil(target).convert('RGB')\n",
    "    im = PIL.Image.new(mode=\"RGB\", size=(512, 512), color='white')\n",
    "    im.paste(target_p.resize((256, 256)), (128, 128, 384, 384))\n",
    "    target = im\n",
    "\n",
    "    new_source_p =  url_to_pil(new_source).convert('RGB')\n",
    "    im = PIL.Image.new(mode=\"RGB\", size=(512, 512), color='white')\n",
    "    im.paste(new_source_p.resize((256,256)), (0, 0, 256, 256))\n",
    "    new_source = im\n",
    "\n",
    "    source = image_transform(source)\n",
    "    target = image_transform(target)\n",
    "    new_source = image_transform(new_source)\n",
    "    grid = create_grid_from_images(source, target, new_source, new_source)\n",
    "    grid = (grid - imagenet_mean[:,None,None]) / imagenet_std[:, None,None]\n",
    "    grid = grid[np.newaxis, :, :, :]\n",
    "    ids_shuffle, len_keep = generate_mask_for_evaluation()\n",
    "    grid = grid.to('cuda')\n",
    "    orig_image, im_paste, mask = generate_image(grid, model, ids_shuffle.to('cuda'), len_keep, device='cuda')\n",
    "    plt.figure(figsize=(8, 6), dpi=80)\n",
    "    return PIL.Image.fromarray(np.uint8(np.clip(im_paste.detach().cpu().numpy(), 0, 255)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352d5a0",
   "metadata": {},
   "source": [
    "# Run model on internet images, manully construct the visual prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40843b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macke\\AppData\\Local\\Temp\\ipykernel_19244\\3324002610.py:20: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  grid = (grid - imagenet_mean[:,None,None]) / imagenet_std[:, None,None]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m target =\u001b[33m\"\u001b[39m\u001b[33mhttps://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/06/14/ML-8362-image003-300.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m new_source = \u001b[33m\"\u001b[39m\u001b[33mhttps://static.scientificamerican.com/sciam/cache/file/1E3A3E62-B3CA-434A-8C3B3ED0C982FB69_source.jpg?w=590&h=800&C8DB8C57-989B-4118-AE27EF1191E878A5\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_source\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(source, target, new_source)\u001b[39m\n\u001b[32m     21\u001b[39m grid = grid[np.newaxis, :, :, :]\n\u001b[32m     22\u001b[39m ids_shuffle, len_keep = generate_mask_for_evaluation()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m grid = \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m orig_image, im_paste, mask = generate_image(grid, model, ids_shuffle.to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m), len_keep, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m6\u001b[39m), dpi=\u001b[32m80\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\macke\\Desktop\\BachelorArbeit\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "source = \"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/06/14/ML-8362-image001-300.jpg\"\n",
    "target =\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/06/14/ML-8362-image003-300.png\"\n",
    "new_source = \"https://static.scientificamerican.com/sciam/cache/file/1E3A3E62-B3CA-434A-8C3B3ED0C982FB69_source.jpg?w=590&h=800&C8DB8C57-989B-4118-AE27EF1191E878A5\"\n",
    "run_model(source, target, new_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5250a",
   "metadata": {},
   "source": [
    "# Segmentation, colorization, style transfer examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf0b8b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_model_single_img\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://yossigandelsman.github.io/visual_prompt/sup/assets/segmentation/0_31_BEIT.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mrun_model_single_img\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m     32\u001b[39m grid = img[np.newaxis, :, :, :]\n\u001b[32m     35\u001b[39m ids_shuffle, len_keep = generate_mask_for_evaluation()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m grid = \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m orig_image, im_paste, mask = generate_image(grid, model, ids_shuffle.to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m), len_keep, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     38\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m6\u001b[39m), dpi=\u001b[32m80\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\macke\\Desktop\\BachelorArbeit\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "run_model_single_img('https://yossigandelsman.github.io/visual_prompt/sup/assets/segmentation/0_31_BEIT.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722191b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_single_img('https://yossigandelsman.github.io/visual_prompt/sup/assets/colorization/1177.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64873d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_single_img(\"https://yossigandelsman.github.io/visual_prompt/sup/assets/other/tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b7980",
   "metadata": {},
   "source": [
    "# Run model on internet images. Shifted apple, this is an example failure case of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "source = \"https://st2.depositphotos.com/7036298/10694/i/450/depositphotos_106948346-stock-photo-ripe-red-apple-with-green.jpg\"\n",
    "target =\"https://st2.depositphotos.com/7036298/10694/i/450/depositphotos_106948346-stock-photo-ripe-red-apple-with-green.jpg\"\n",
    "new_source = \"https://www.quanta.org/orange/orange.jpg\"\n",
    "run_model_with_variable_placements(source, target, new_source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
